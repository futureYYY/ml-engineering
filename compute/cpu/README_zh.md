# README - 中文翻译

# CPU

截至撰写本文时，机器学习负载对CPU的使用不多，因此在这章中没有太多内容可讲述。随着CPU的发展逐渐向GPU靠拢，这种情况可能会发生变化，所以我预计这章会随着CPU的发展而演变。

## 需要多少个CPU核心

每1个加速器需要：

1. 每个绑定到加速器的进程需要1个CPU核心。
2. 每个`DataLoader`工作进程需要1个CPU核心——通常你需要2-4个工作进程。

对于语言模型（LMs），2个工作进程通常已经足够，特别是如果数据已经预处理过的话。

如果你需要进行动态变换，这在计算机视觉模型或VLMs中通常是必要的，你可能需要3-4个甚至更多的工作进程。

目标是能够从`DataLoader`即时获取数据，并且不阻塞加速器的计算，这意味着你需要为下一次迭代预先处理一批样本，同时当前迭代正在运行。换句话说，你的下一个批次的处理时间不应超过相同大小批次的单次加速器计算时间。

除了预处理之外，如果你是从云存储而不是本地存储中动态拉取数据，还需要确保数据预取得足够快，以满足喂入加速器工作的需要。

将上述需求乘以加速器的数量，并加上几个用于操作系统的内核（假设为4个）。

如果节点有8个加速器，并且你有n_workers个工作者进程，那么你需要`8*(num_workers+1)+4`个CPU核心。如果你做的是NLP任务，通常每个加速器需要约2个工作进程，所以`8*(2+1)+4` => 28个CPU核心。如果你做的是CV训练，并且每个加速器需要4个工作进程，那么就是`8*(4+1)+4` => 44个CPU核心。

如果你的活跃进程数量超过了总CPU核心数，一些进程会被抢占（放入队列，等待CPU核心可用）。你绝对希望避免任何上下文切换。

但是现代云服务通常提供50-100+个CPU核心，因此通常有足够的核心来满足需求。

参见[异步DataLoader](../../training/performance#asynchronous-dataloader)。

### CPU卸载

一些框架，如[Deepspeed](https://www.deepspeed.ai/tutorials/zero-offload/)，可以在不造成瓶颈的情况下将一些计算工作卸载到CPU。在这种情况下，你可能需要额外的CPU核心。

### NUMA亲和性

参见[NUMA亲和性](../../training/performance#numa-affinity)。

### 超线程

[超线程](https://en.wikipedia.org/wiki/Hyper-threading)通过将每个物理核心虚拟化为两个虚拟核心，使每个物理核心可以同时运行两个线程，从而将CPU核心数量翻倍。根据工作负载的不同，这项技术可能会也可能不会提高整体性能。发明这项技术的英特尔建议，在某些情况下，可能有高达30%的性能提升。

参见[是否启用超线程](../../orchestration/slurm/performance.md#to-enable-hyper-threads-or-not)。