# README - 中文翻译

# CPU内存

这是一小节，因为通常关于CPU内存需要了解的细节很少——这是一件好事！

大多数机器学习工作负载计算是在GPU上进行的，但每个节点上的CPU内存至少应该和GPU一样多。例如，如果你在一个有8块80GB GPU的H100节点上，你将拥有640GB的GPU内存。因此，你至少需要同样数量的CPU内存。但最近的高端云服务包通常会提供1到2TB的CPU内存。

## 机器学习工作负载中CPU内存的需求

- 加载模型权重，除非它们直接加载到GPU上——这通常是临时内存使用，一旦模型被移到GPU上就会归零。
- 保存模型权重。在某些情况下，每个GPU会直接将检查点写入磁盘，在其他情况下，模型会在写入磁盘前在CPU上重组——这也是临时内存使用。
- 使用像[Deepspeed](https://www.deepspeed.ai/tutorials/zero-offload/)这样的框架时，可能需要卸载参数和优化器状态。在这种情况下，可能需要大量的CPU内存。
- 在`forward`传递中计算的激活值，需要在`backward`路径中可用，也可以卸载到CPU上，而不是在反向传播过程中丢弃并重新计算以节省不必要的开销。
- `DataLoader`通常是CPU内存的主要使用者之一，有时可能会消耗大量内存。通常每个节点至少运行2个8个DL工作者，因此你需要足够的内存来支持至少16个进程，每个进程都持有某些数据。例如，在从云端流式传输数据的情况下，如果数据分片很大，这些进程很容易消耗数百GB的CPU内存。
- 软件本身及其依赖库也会占用一些CPU内存，但这个量通常可以忽略不计。

## 需要知道的事项

- 如果`DataLoader`使用HF `datasets`的`mmap`模式，驻留内存使用量可能会显得使用了大量的CPU内存，因为它试图将整个数据集映射到内存中。但这具有误导性，因为如果内存需要用于其他地方，操作系统会将不需要的`mmap`页面换出到系统中。你可以在这里阅读更多相关信息：[这里](https://stasosphere.com/entrepreneur-being/301-mmap-memory-leak-investigation/)。当然，这种认识适用于任何使用`mmap`的数据集，我用HF `datasets`作为例子，因为它非常常用。